{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INSTALL IF YOU DON'T HAVE SURPRISE ON YOUR MACHINE AND WOULD LIKE TO RUN THE CODE\n",
    "# !pip install surprise\n",
    "# !pip install import-ipynb\n",
    "\n",
    "# !kaggle datasets download netflix-inc/netflix-prize-data\n",
    "# !mkdir \"data\"\n",
    "# !mkdir \"data/original\"\n",
    "# import zipfile\n",
    "# with zipfile.ZipFile(\"netflix-prize-data.zip\",\"r\") as zip_ref:\n",
    "#     zip_ref.extractall(\"data/original/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise import dataset, KNNBaseline, accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "import pickle\n",
    "from random import *\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict\n",
    "from surprise import KNNBasic\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "import NetflixLoadData as NetflixLoadData\n",
    "\n",
    "from surprise import dataset, KNNBaseline, accuracy\n",
    "from surprise.model_selection import train_test_split, LeaveOneOut\n",
    "\n",
    "use_pickle_file = True\n",
    "reader = Reader(line_format='user item rating', rating_scale=(1, 5))\n",
    "\n",
    "def save_to_pickle(name, df):\n",
    "    path_name = \"pickle/\"+name+\".pickle\"\n",
    "    pickle_file = open(path_name,\"wb\")\n",
    "    pickle.dump(df, pickle_file)\n",
    "    pickle_file.close()\n",
    "\n",
    "def load_pickle(name):\n",
    "    path_name = \"pickle/\"+name+\".pickle\"\n",
    "    return_input = open(path_name, \"rb\")\n",
    "    return pickle.load(return_input)\n",
    "\n",
    "# IF THIS IS YOUR FIRST RUN [uncomment next line, and change to how many files you want to work with (choices are 1 to 4) from original kaggle netflix price dataset (less is faster)]\n",
    "#NetflixLoadData.first_time_running(max_files=4)\n",
    "\n",
    "how_many_files_do_you_want_to_use = 1 #choices are 1 to 4\n",
    "movie_titles, ratings, movie_and_rating = NetflixLoadData.get_data(number_of_files_of_rating=how_many_files_do_you_want_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_id_rows(df, type, item_id):\n",
    "    return df[df[type] == item_id]\n",
    "\n",
    "def all_average_ratings(df, type='movie_id'):\n",
    "    ratings_stats = df.groupby(type).agg({'rating': ['sum', 'count']}).reset_index()\n",
    "    ratings_stats['avg_rating'] =  ratings_stats['rating']['sum'] / ratings_stats['rating']['count']\n",
    "    return ratings_stats\n",
    "\n",
    "def customer_average_ratings(df, type='customer_id', customer_id=0):\n",
    "    ratings_stats = df[df[type]==customer_id].groupby(type).agg({'rating': ['sum', 'count']}).reset_index()\n",
    "    ratings_stats['avg_rating'] =  ratings_stats['rating']['sum'] / ratings_stats['rating']['count']\n",
    "    return ratings_stats\n",
    "\n",
    "def all_get_rated_count(df, type):\n",
    "    return df.groupby(type).agg({'movie_id': 'count'}).reset_index()\n",
    "\n",
    "def get_avg_rating_less_than(df, max_rating):\n",
    "    return df[df['avg_rating'] < max_rating]\n",
    "\n",
    "def get_avg_rating_higher_than(df, min_rating):\n",
    "    return df[df['avg_rating'] > min_rating]\n",
    "\n",
    "def get_item_avg_rating(df, type, item_id):\n",
    "    return df[df[type] == item_id]\n",
    "\n",
    "\n",
    "def get_movies_customer_rated_higher_than(df, customer_id, min_rating=4): \n",
    "    #df is equal to data_rating_plus_movie_title\n",
    "    temp = df.copy()\n",
    "    return temp[(temp['customer_id'] == customer_id) & (temp['rating'] >= min_rating)].set_index('movie_id')\n",
    "\n",
    "def get_movies_customer_rated_lower_than(df, customer_id, max_rating=4):\n",
    "    #df is equal to data_rating_plus_movie_title\n",
    "    temp = df.copy()\n",
    "    return temp[(temp['customer_id'] == customer_id) & (temp['rating'] < max_rating)].set_index('movie_id')\n",
    "\n",
    "\n",
    "def display_movies_customer_rated_higher_than(df, customer_id, min_rating=4):\n",
    "    #df is equal to data_rating_plus_movie_title\n",
    "    df_customer_liked = get_movies_customer_rated_higher_than(df=df, customer_id=customer_id, min_rating=min_rating)\n",
    "    print(df_customer_liked[['movie_title', 'rating']])\n",
    "    customers_ratings_stats = df.groupby('customer_id').agg({'rating': ['sum', 'count']}).reset_index()\n",
    "    customers_ratings_stats['avg_rating'] =  customers_ratings_stats['rating']['sum'] / customers_ratings_stats['rating']['count']\n",
    "    print('average rating', customers_ratings_stats[customers_ratings_stats['customer_id'] == customer_id]['avg_rating'])\n",
    "\n",
    "def display_movies_customer_rated_lower_than(df, customer_id, max_rating=4):\n",
    "    #df is equal to data_rating_plus_movie_title\n",
    "    df_customer_disliked = get_movies_customer_rated_lower_than(df, customer_id=customer_id, max_rating=max_rating)\n",
    "    print(df_customer_disliked[['movie_title', 'rating']])\n",
    "    customers_ratings_stats = df.groupby('customer_id').agg({'rating': ['sum', 'count']}).reset_index()\n",
    "    customers_ratings_stats['avg_rating'] =  customers_ratings_stats['rating']['sum'] / customers_ratings_stats['rating']['count']\n",
    "    print('average rating', customers_ratings_stats[customers_ratings_stats['customer_id'] == customer_id]['avg_rating'])\n",
    "\n",
    "\n",
    "def get_users_loved_hated_movies(df, customer_id, minmax_rating):\n",
    "    users_ratings_higher_than_four = get_movies_customer_rated_higher_than(df=df, customer_id=customer_id, min_rating=minmax_rating)\n",
    "    users_ratings_lower_than_four = get_movies_customer_rated_lower_than(df=df, customer_id=customer_id, max_rating=minmax_rating)\n",
    "    print(\"User\", customer_id ,\"loved these movies\")\n",
    "    for rating in users_ratings_higher_than_four['movie_title']:\n",
    "        print(rating)\n",
    "    print('')\n",
    "    print(\"and disliked these movies\")\n",
    "    for rating in users_ratings_lower_than_four['movie_title']:\n",
    "        print(rating)\n",
    "\n",
    "#def get_customers_who_rated_movie_title(df=data_rating_plus_movie_title, movie_title=\"\"):\n",
    "def get_customers_who_rated_movie_title(df, movie_title=\"\"):\n",
    "    return df[df[\"movie_title\"] == movie_title]\n",
    "\n",
    "#def get_avg_rating_for_movie_title(df=data_movies, movie_title=\"\"):\n",
    "def get_avg_rating_for_movie_title(df, movie_title=\"\"):\n",
    "    tmp_data_movies = df[df[\"movie_title\"] == movie_title]\n",
    "    tmp_movie_id = tmp_data_movies['movie_id'].values[0]\n",
    "    tmp_data_movies.columns = pd.MultiIndex.from_product([['movie_id'], tmp_data_movies.columns])\n",
    "    all_movies_average_rating = all_average_ratings(df=data_rating, type='movie_id')\n",
    "    return get_item_avg_rating(df=all_movies_average_rating , type='movie_id', item_id=tmp_movie_id).join(tmp_data_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>movie_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>822109</td>\n",
       "      <td>5</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>885013</td>\n",
       "      <td>4</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30878</td>\n",
       "      <td>4</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>823519</td>\n",
       "      <td>3</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053759</th>\n",
       "      <td>4499</td>\n",
       "      <td>2591364</td>\n",
       "      <td>2</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>In My Skin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053760</th>\n",
       "      <td>4499</td>\n",
       "      <td>1791000</td>\n",
       "      <td>2</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>In My Skin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053761</th>\n",
       "      <td>4499</td>\n",
       "      <td>512536</td>\n",
       "      <td>5</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>In My Skin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053762</th>\n",
       "      <td>4499</td>\n",
       "      <td>988963</td>\n",
       "      <td>3</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>In My Skin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053763</th>\n",
       "      <td>4499</td>\n",
       "      <td>1704416</td>\n",
       "      <td>3</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>In My Skin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24053764 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          movie_id  customer_id  rating  movie_year      movie_title\n",
       "0                1      1488844       3      2003.0  Dinosaur Planet\n",
       "1                1       822109       5      2003.0  Dinosaur Planet\n",
       "2                1       885013       4      2003.0  Dinosaur Planet\n",
       "3                1        30878       4      2003.0  Dinosaur Planet\n",
       "4                1       823519       3      2003.0  Dinosaur Planet\n",
       "...            ...          ...     ...         ...              ...\n",
       "24053759      4499      2591364       2      2002.0       In My Skin\n",
       "24053760      4499      1791000       2      2002.0       In My Skin\n",
       "24053761      4499       512536       5      2002.0       In My Skin\n",
       "24053762      4499       988963       3      2002.0       In My Skin\n",
       "24053763      4499      1704416       3      2002.0       In My Skin\n",
       "\n",
       "[24053764 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_and_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations with collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation_accuracy(predictions):\n",
    "    print(\"\\nEvaluating accuracy of model...\")\n",
    "    print(\"RMSE: \", accuracy.rmse(predictions, verbose=False))\n",
    "    print(\"MSE: \", accuracy.mse(predictions, verbose=False))\n",
    "    print(\"MAE: \", accuracy.mae(predictions, verbose=False))\n",
    "    # FCP = Fraction of Concordant Pairs\n",
    "    print(\"FCP: \", accuracy.mae(predictions, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23240346"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24053764-813418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_df(movie_and_rating[['customer_id', 'movie_id', 'rating']], reader)\n",
    "fullTrainset = dataset.build_full_trainset()\n",
    "trainSet, testSet = train_test_split(dataset, test_size=.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.58 TiB for an array with shape (465545, 465545) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m knn_basic \u001b[39m=\u001b[39m KNNBasic(K\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(trainSet)\n\u001b[1;32m      2\u001b[0m knn_basic_predictions \u001b[39m=\u001b[39m knn_basic\u001b[39m.\u001b[39mtest(testSet)\n\u001b[1;32m      3\u001b[0m print_evaluation_accuracy(knn_basic_predictions)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/surprise/prediction_algorithms/knns.py:98\u001b[0m, in \u001b[0;36mKNNBasic.fit\u001b[0;34m(self, trainset)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, trainset):\n\u001b[1;32m     97\u001b[0m     SymmetricAlgo\u001b[39m.\u001b[39mfit(\u001b[39mself\u001b[39m, trainset)\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msim \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_similarities()\n\u001b[1;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/surprise/prediction_algorithms/algo_base.py:248\u001b[0m, in \u001b[0;36mAlgoBase.compute_similarities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    247\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mComputing the \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m similarity matrix...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 248\u001b[0m sim \u001b[39m=\u001b[39m construction_func[name](\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    249\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    250\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone computing similarity matrix.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/surprise/similarities.pyx:125\u001b[0m, in \u001b[0;36msurprise.similarities.msd\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 1.58 TiB for an array with shape (465545, 465545) and data type float64"
     ]
    }
   ],
   "source": [
    "knn_basic = KNNBasic(K=40).fit(trainSet)\n",
    "knn_basic_predictions = knn_basic.test(testSet)\n",
    "print_evaluation_accuracy(knn_basic_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatasetAutoFolds' object has no attribute 'DatasetAutoFolds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFCP: \u001b[39m\u001b[39m\"\u001b[39m, accuracy\u001b[39m.\u001b[39mmae(predictions, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n\u001b[1;32m     21\u001b[0m \u001b[39m#here is my custom function\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mconvert_to_raw_ratings\u001b[39;00m(dataset\u001b[39m.\u001b[39;49mDatasetAutoFolds):\n\u001b[1;32m     23\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, df, reader):\n\u001b[1;32m     24\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_ratings \u001b[39m=\u001b[39m [(uid, iid, r, \u001b[39mNone\u001b[39;00m) \u001b[39mfor\u001b[39;00m (uid, iid, r) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(df[\u001b[39m'\u001b[39m\u001b[39mcustomer_id\u001b[39m\u001b[39m'\u001b[39m], df[\u001b[39m'\u001b[39m\u001b[39mmovie_id\u001b[39m\u001b[39m'\u001b[39m], df[\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m])]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DatasetAutoFolds' object has no attribute 'DatasetAutoFolds'"
     ]
    }
   ],
   "source": [
    "## creating a test function to see if there is any difference in creating a custom function or just use the default\n",
    "# here is the default way\n",
    "def test_against_our_custom_function():\n",
    "    _, data_rating, _, _ = NetflixLoadData.get_data_files(use_small_dataset=True)\n",
    "    dataset = Dataset.load_from_df(data_rating[['customer_id', 'movie_id', 'rating']], reader)\n",
    "    fullTrainset = dataset.build_full_trainset()\n",
    "\n",
    "    trainSet, testSet = train_test_split(dataset, test_size=.25, random_state=1)\n",
    "\n",
    "    algo = SVD(random_state=10)\n",
    "    algo.fit(trainSet)\n",
    "\n",
    "    predictions = algo.test(testSet)\n",
    "    print(\"\\nEvaluating accuracy of model...\")\n",
    "    print(\"RMSE: \", accuracy.rmse(predictions, verbose=False))\n",
    "    print(\"MSE: \", accuracy.mse(predictions, verbose=False))\n",
    "    print(\"MAE: \", accuracy.mae(predictions, verbose=False))\n",
    "    # FCP = Fraction of Concordant Pairs\n",
    "    print(\"FCP: \", accuracy.mae(predictions, verbose=False))\n",
    "\n",
    "#here is my custom function\n",
    "class convert_to_raw_ratings(dataset.DatasetAutoFolds):\n",
    "    def __init__(self, df, reader):\n",
    "        self.raw_ratings = [(uid, iid, r, None) for (uid, iid, r) in zip(df['customer_id'], df['movie_id'], df['rating'])]\n",
    "\n",
    "#raw_ratings = convert_to_raw_ratings(data_rating, reader)\n",
    "#print(\"\\nBuilding recommendation model...\")\n",
    "#trainSet, testSet = train_test_split(raw_ratings, test_size=.25, random_state=1)\n",
    "\n",
    "#algo = SVD(random_state=10)\n",
    "#algo.fit(trainSet)\n",
    "#algo_predictions = algo.test(testSet)\n",
    "\n",
    "#test_against_our_custom_function()\n",
    "#print_evaluation_accuracy(algo_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating accuracy of model...\n",
      "RMSE:  0.9031234558172019\n",
      "MSE:  0.8156319764472053\n",
      "MAE:  0.6975635778170713\n",
      "FCP:  0.6975635778170713\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# dataset = Dataset.load_from_df(movie_and_rating[['customer_id', 'movie_id', 'rating']], reader)\n",
    "# fullTrainset = dataset.build_full_trainset()\n",
    "# trainSet, testSet = train_test_split(dataset, test_size=.25, random_state=1)\n",
    "algo = SVD(random_state=10)\n",
    "algo.fit(trainSet)\n",
    "\n",
    "predictions = algo.test(testSet)\n",
    "print(\"\\nEvaluating accuracy of model...\")\n",
    "print(\"RMSE: \", accuracy.rmse(predictions, verbose=False))\n",
    "print(\"MSE: \", accuracy.mse(predictions, verbose=False))\n",
    "print(\"MAE: \", accuracy.mae(predictions, verbose=False))\n",
    "# FCP = Fraction of Concordant Pairs\n",
    "print(\"FCP: \", accuracy.mae(predictions, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb60acc68106785d00a40fb3b1b3b80d861e6f0b0d60f9d8440fa3d46ca2822c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
